<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Information Retrieval note | Yuyz-Cyber</title><meta name="author" content="yuyz"><meta name="copyright" content="yuyz"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Information RetrievalChapter 10x00 Information Retrieval and Some ConceptThe Goal of Information Retrievalis to retrieve documents from a corpus that are relevant to the user’s information needs, whic">
<meta property="og:type" content="article">
<meta property="og:title" content="Information Retrieval note">
<meta property="og:url" content="http://example.com/2024/09/09/Information-Retrieval-note/index.html">
<meta property="og:site_name" content="Yuyz-Cyber">
<meta property="og:description" content="Information RetrievalChapter 10x00 Information Retrieval and Some ConceptThe Goal of Information Retrievalis to retrieve documents from a corpus that are relevant to the user’s information needs, whic">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2024-09-09T14:02:06.000Z">
<meta property="article:modified_time" content="2024-09-23T09:19:27.989Z">
<meta property="article:author" content="yuyz">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2024/09/09/Information-Retrieval-note/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Information Retrieval note',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-09-23 17:19:27'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><hr class="custom-hr"/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Yuyz-Cyber"><span class="site-name">Yuyz-Cyber</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Information Retrieval note</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-09-09T14:02:06.000Z" title="Created 2024-09-09 22:02:06">2024-09-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-09-23T09:19:27.989Z" title="Updated 2024-09-23 17:19:27">2024-09-23</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Information Retrieval note"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Information-Retrieval"><a href="#Information-Retrieval" class="headerlink" title="Information Retrieval"></a>Information Retrieval</h1><h2 id="Chapter-1"><a href="#Chapter-1" class="headerlink" title="Chapter 1"></a>Chapter 1</h2><h3 id="0x00-Information-Retrieval-and-Some-Concept"><a href="#0x00-Information-Retrieval-and-Some-Concept" class="headerlink" title="0x00 Information Retrieval and Some Concept"></a>0x00 Information Retrieval and Some Concept</h3><h4 id="The-Goal-of-Information-Retrieval"><a href="#The-Goal-of-Information-Retrieval" class="headerlink" title="The Goal of Information Retrieval"></a>The Goal of Information Retrieval</h4><p>is to retrieve documents from a corpus that are relevant to the user’s information needs, which are communicated to the system through a one-off query initiated by the user.</p>
<h4 id="Definition-of-Information-Retrieval"><a href="#Definition-of-Information-Retrieval" class="headerlink" title="Definition of Information Retrieval"></a>Definition of Information Retrieval</h4><p>Information retrieval is the process of finding materials (usually documents) that meet the user’s information needs from a large collection of unstructured data (usually text), typically stored on computers.</p>
<ul>
<li><p><strong>Unstructured Data</strong>: Refers to data that lacks a clear and explicit semantic structure, making it difficult for computers to process.</p>
</li>
<li><p><strong>Structured Data</strong>: In contrast to unstructured data, such as relational databases.</p>
</li>
<li><p><strong>Semi-structured Data</strong>: Refers to data that includes format markers, such as web pages.</p>
</li>
</ul>
<h4 id="Use-cases-of-Information-Retrieval"><a href="#Use-cases-of-Information-Retrieval" class="headerlink" title="Use cases of Information Retrieval"></a>Use cases of Information Retrieval</h4><ul>
<li>Fast searching within large-scale document collections</li>
<li>More flexible matching methods</li>
<li>The need to rank results</li>
</ul>
<h5 id="Ad-hoc-retrieval-task"><a href="#Ad-hoc-retrieval-task" class="headerlink" title="Ad hoc retrieval task:"></a>Ad hoc retrieval task:</h5><p>A user’s information need is communicated to the system through a one-time query submitted by the user, and the system returns documents relevant to that query from a collection of documents.</p>
<h4 id="How-to-Evaluating-the-effectiveness-of-a-retrieval-system-the-quality-of-search-results-："><a href="#How-to-Evaluating-the-effectiveness-of-a-retrieval-system-the-quality-of-search-results-：" class="headerlink" title="How to Evaluating the effectiveness of a retrieval system (the quality of search results)："></a>How to Evaluating the effectiveness of a retrieval system (the quality of search results)：</h4><p>using <strong>Precision</strong> and <strong>Recall</strong></p>
<h3 id="some-nouns"><a href="#some-nouns" class="headerlink" title="some nouns"></a>some nouns</h3><ul>
<li><h5 id="corpus"><a href="#corpus" class="headerlink" title="corpus"></a>corpus</h5></li>
</ul>
<p>A corpus is a large, structured text dataset used to support language processing tasks and research，also called (document) collection.</p>
<ul>
<li><h5 id="Term-document-incidence-matrix"><a href="#Term-document-incidence-matrix" class="headerlink" title="Term-document incidence matrix"></a>Term-document incidence matrix</h5></li>
</ul>
<p>The term-document incidence matrix is a binary matrix used in information retrieval and text mining to represent the presence or absence of terms within documents.</p>
<p>Matrix element (t, d) is 1 if the play in column d contains the word in row t, and is 0 otherwise. Here is an example:</p>
<table>
<thead>
<tr>
<th></th>
<th>D1</th>
<th>D2</th>
</tr>
</thead>
<tbody><tr>
<td>T1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>T2</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>T3</td>
<td>1</td>
<td>1</td>
</tr>
</tbody></table>
<h3 id="0x01-inverted-index"><a href="#0x01-inverted-index" class="headerlink" title="0x01 inverted index"></a>0x01 inverted index</h3><p>In fact, the term-document matrix is typically sparse, so it is represented using an <strong>inverted index</strong>.</p>
<p>An inverted index maps keywords (or terms) to a list of documents containing those keywords. The inverted index consists of a vocabulary (a list of terms) and an inverted list (a list of documents for each term). Each term in the vocabulary has an inverted list that enumerates all the documents containing that term and their positions within the documents.</p>
<p><strong>Inverted Index Overview</strong>:</p>
<ol>
<li><p><strong>Vocabulary</strong>:</p>
<ul>
<li>The vocabulary is a list of terms that appear in the documents.</li>
<li>Each term in the vocabulary has a unique identifier used to locate it in the inverted list.</li>
</ul>
</li>
<li><p><strong>Inverted List</strong>:</p>
<ul>
<li>For each term in the vocabulary, there is an inverted list.</li>
<li>The inverted list records all documents containing the term and the positions of the term within those documents (sometimes including the term’s frequency).</li>
</ul>
</li>
</ol>
<p><strong>How an Inverted Index Works</strong>:</p>
<ol>
<li><p><strong>Document Processing</strong>:</p>
<ul>
<li>Each document is tokenized into terms.</li>
<li>Additional preprocessing steps may include removing stop words, stemming, etc.</li>
</ul>
</li>
<li><p><strong>Building Vocabulary and Inverted Lists</strong>:</p>
<ul>
<li>Traverse all documents to build the vocabulary.</li>
<li>For each term, create an inverted list that includes all documents containing the term and the term’s positions in those documents.</li>
</ul>
</li>
</ol>
<p><strong>Example</strong>:</p>
<p>Suppose we have the following three documents:</p>
<ol>
<li>Document 1: “Information retrieval is an important field in computer science.”</li>
<li>Document 2: “An inverted index is an efficient data structure.”</li>
<li>Document 3: “Information retrieval technology is widely used in modern search engines.”</li>
</ol>
<p>After <strong>tokenization</strong>, we obtain the following terms（<strong>token</strong>）:</p>
<ul>
<li>“Information retrieval”</li>
<li>“Computer science”</li>
<li>“Important”</li>
<li>“Field”</li>
<li>“Inverted index”</li>
<li>“Efficient”</li>
<li>“Data structure”</li>
<li>“Technology”</li>
<li>“Modern”</li>
<li>“Search engines”</li>
<li>“Widely”</li>
<li>“Used”</li>
</ul>
<p>The vocabulary and its corresponding inverted lists would be:</p>
<ul>
<li>“Information retrieval”: [Document 1, Document 3]</li>
<li>“Computer science”: [Document 1]</li>
<li>“Important”: [Document 1]</li>
<li>“Field”: [Document 1]</li>
<li>“Inverted index”: [Document 2]</li>
<li>“Efficient”: [Document 2]</li>
<li>“Data structure”: [Document 2]</li>
<li>“Technology”: [Document 3]</li>
<li>“Modern”: [Document 3]</li>
<li>“Search engines”: [Document 3]</li>
<li>“Widely”: [Document 3]</li>
<li>“Used”: [Document 3]</li>
</ul>
<p><img src="C:\Users\zyy23\AppData\Roaming\Typora\typora-user-images\image-20240907170858130.png"></p>
<p>For an in-memory inverted index, there are two effective storage methods:</p>
<ol>
<li><p><strong>Singly Linked List</strong>: This method facilitates the insertion and updating of documents (e.g., re-crawling updated web pages). By adding pointers, it can naturally extend to more advanced indexing strategies.</p>
</li>
<li><p><strong>Variable Length Array</strong>: On one hand, it saves space by avoiding the overhead of pointers. On the other hand, because it uses contiguous memory storage, it can leverage modern computer cache techniques to improve access speed.</p>
</li>
</ol>
<h3 id="0x02-Boolean-retrieval-model"><a href="#0x02-Boolean-retrieval-model" class="headerlink" title="0x02 Boolean retrieval model"></a>0x02 Boolean retrieval model</h3><h4 id="Boolean-retrieval-model"><a href="#Boolean-retrieval-model" class="headerlink" title="Boolean retrieval model"></a><strong>Boolean retrieval model</strong></h4><p> Based on Boolean logic to handle query and document matching, it stores document relationships using vectors and constructs queries with Boolean operators (such as AND, OR, NOT).</p>
<p>The <strong>intersection</strong> operation algorithm is very crucial:</p>
<p><img src="C:\Users\zyy23\AppData\Roaming\Typora\typora-user-images\image-20240908143958543.png"></p>
<h4 id="Query-optimization"><a href="#Query-optimization" class="headerlink" title="Query optimization"></a><strong>Query optimization</strong></h4><p>refers to organizing the query processing in a way that minimizes the workload. One key factor to consider when optimizing Boolean queries is the access order of the inverted index records.</p>
<p><img src="C:\Users\zyy23\AppData\Roaming\Typora\typora-user-images\image-20240908144521364.png" alt="image-20240908144521364"></p>
<h3 id="0x03-The-extended-Boolean-model-versus-ranked-retrieval"><a href="#0x03-The-extended-Boolean-model-versus-ranked-retrieval" class="headerlink" title="0x03 The extended Boolean model versus ranked retrieval"></a>0x03 The extended Boolean model versus ranked retrieval</h3><h4 id="ranked-retrieval-model"><a href="#ranked-retrieval-model" class="headerlink" title="ranked retrieval model"></a><strong>ranked retrieval model</strong></h4><p>Rank the retrieval results based on the relevance between documents and queries. In this model, each document is scored according to its match with the query, and then sorted by score from highest to lowest, returning the most relevant documents.</p>
<p>such as : TF-IDF</p>
<h4 id="proximity-operator"><a href="#proximity-operator" class="headerlink" title="proximity operator"></a><strong>proximity operator</strong></h4><p>is used to specify that two terms in a query should be close to each other within a document. The degree of proximity is usually measured by the number of words between the terms or whether they appear within the same structural unit (such as a sentence or paragraph).</p>
<h4 id="A-common-issue-with-Boolean-search"><a href="#A-common-issue-with-Boolean-search" class="headerlink" title="A common issue with Boolean search"></a>A common issue with Boolean search</h4><p>is that results produced with the AND operator have high precision but low recall, while those produced with the OR operator have high recall but low precision. Finding a satisfactory compromise between these two metrics is difficult, if not impossible.</p>
<h3 id="0x04-Summarize"><a href="#0x04-Summarize" class="headerlink" title="0x04 Summarize"></a>0x04 Summarize</h3><p>Chapter 1 introduces the need for information retrieval through the case of Shakespeare, highlighting the limitations of traditional relational databases in handling large document collections: the demand for fast retrieval, flexible matching methods, and the necessity of result ranking. The chapter then offers a comprehensive definition of information retrieval.</p>
<p>For large-scale web documents, creating an index for all documents is essential. When users search with specific keywords, the system operates on the index to swiftly retrieve results, significantly reducing retrieval time and avoiding redundant computations.</p>
<p>The chapter introduces two indexing methods: the term-document association matrix and the inverted index. Since the term-document matrix is often sparse, with many zero values, the inverted index is typically considered the more efficient choice.</p>
<p>It also outlines the basic workflow of the information retrieval model, from tokenization and building the inverted index to simple query execution. Additionally, the chapter discusses common Boolean retrieval model, relevant algorithms, optimization techniques, and compares the strengths and weaknesses of AND and OR in terms of precision and recall.</p>
<h2 id="Chapter-2-Lexicon-and-Inverted-Index"><a href="#Chapter-2-Lexicon-and-Inverted-Index" class="headerlink" title="Chapter 2: Lexicon and Inverted Index"></a>Chapter 2: Lexicon and Inverted Index</h2><h3 id="0x00-Introduction"><a href="#0x00-Introduction" class="headerlink" title="0x00 Introduction"></a>0x00 Introduction</h3><h4 id="content"><a href="#content" class="headerlink" title="content"></a>content</h4><p><img src="C:\Users\zyy23\AppData\Roaming\Typora\typora-user-images\image-20240917213232114.png" alt="image-20240917213232114"></p>
<h4 id="Key-words"><a href="#Key-words" class="headerlink" title="Key words"></a>Key words</h4><p><strong>Documen unit</strong>: The minimum index uni. In previous chapters, the default document unit is a document.<br><strong>Token</strong>: The output of Tokenization. It is a word after document Tokenization.<br>Term: After token normalization, we get token sets with different glyphs but same meanings.<br><strong>Stop word</strong>: Extremely common words that would appear to be of little value in helping select documents matching a user need.<br><strong>Token normalization</strong>: The process of canonicalizing tokens so that matches normalization occur despite superfificial differences in the character sequences of the tokens.<br>Stemming: Use some matching rules to restore a variety of deformed words to their original lexicon.<br><strong>Lemmatization</strong>: Put words with the same meaning but different parts of speech into an equivalence class.<br><strong>Skip list</strong>: Based on Posting with some jump Pointers to provide speed improvement for the merge operation.<br><strong>Phrase query</strong>: Use phrases to query and expect to return the words searched in the document to appear consecutively as phrases.<br><strong>Biword indexes</strong>: A method of phrase query that treats two consecutive words in a phrase as a term and indexes it.<br><strong>Positional indexes</strong>: Another method to “query phrases”. By adding the word position information in the Posting, we determine whether the two words constitute a phrase.**</p>
<h3 id="0x01-Document-Analysis-and-Encoding-Conversion"><a href="#0x01-Document-Analysis-and-Encoding-Conversion" class="headerlink" title="0x01 Document Analysis and Encoding Conversion"></a>0x01 Document Analysis and Encoding Conversion</h3><h4 id="Character-Sequence-Generation"><a href="#Character-Sequence-Generation" class="headerlink" title="Character Sequence Generation"></a>Character Sequence Generation</h4><p>The first step in document processing is converting byte sequences into linear character sequences. To do this, it’s essential to accurately determine the document’s encoding. Although this can be viewed as a machine learning classification problem, it is often handled heuristically. Metadata or manual user input may also help determine the encoding.</p>
<p>Once the encoding is identified, the byte sequence can be converted into a character sequence. It’s important to preserve the encoding information, as it may aid in identifying the document’s language. In cases where a document contains both text and non-text components, it may be necessary to extract only the text for processing.</p>
<h5 id="Example"><a href="#Example" class="headerlink" title="Example:"></a>Example:</h5><ul>
<li><strong>Input</strong>: A document in UTF-8 encoding containing text and images.</li>
<li><strong>Action</strong>: Detect the UTF-8 encoding, convert the byte sequence to characters, and extract the text portion for further analysis.</li>
</ul>
<h4 id="Selection-of-Document-Units"><a href="#Selection-of-Document-Units" class="headerlink" title="Selection of Document Units"></a>Selection of Document Units</h4><p>After determining the character sequence, the next step is to define the document unit for indexing. For longer documents, this is known as <em>indexing granularity</em>.</p>
<h5 id="Example-1"><a href="#Example-1" class="headerlink" title="Example:"></a><strong>Example</strong>:</h5><ul>
<li>Fine-grained indexing (e.g., paragraph level) may result in high precision but low recall, as relevant information might be scattered across multiple sections.</li>
<li>Coarse-grained indexing (e.g., document level) may improve recall but reduce precision by retrieving irrelevant content.</li>
</ul>
<h3 id="0x02-Defining-the-Term-Set"><a href="#0x02-Defining-the-Term-Set" class="headerlink" title="0x02 Defining the Term Set"></a>0x02 Defining the Term Set</h3><h4 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h4><p>Once the document units are set, tokenization breaks the character sequence into smaller segments called tokens. Tokens are the individual instances of text in the document.</p>
<h5 id="Example-2"><a href="#Example-2" class="headerlink" title="Example:"></a>Example:</h5><ul>
<li><strong>Input</strong>: “Friends, Romans, Countrymen, lend me your ears;”</li>
<li><strong>Output</strong>: Friends | Romans | Countrymen | lend | me | your | ears</li>
</ul>
<p>In tokenization, punctuation and special characters are typically removed.</p>
<h4 id="Removing-Stop-Words"><a href="#Removing-Stop-Words" class="headerlink" title="Removing Stop Words"></a>Removing Stop Words</h4><p>Some common words are not useful for matching documents to user queries. These are referred to as <em>stop words</em> and are removed from the vocabulary.</p>
<h5 id="Example-3"><a href="#Example-3" class="headerlink" title="Example:"></a>Example:</h5><ul>
<li>Stop words such as “the,” “is,” or “and” may not contribute to search results and are thus excluded from indexing.</li>
</ul>
<h4 id="Token-Normalization"><a href="#Token-Normalization" class="headerlink" title="Token Normalization"></a>Token Normalization</h4><p>Token normalization involves transforming tokens that appear different into a common form for easier matching. The most typical method is to implicitly establish equivalence classes where similar tokens are grouped.</p>
<h5 id="Example-4"><a href="#Example-4" class="headerlink" title="Example:"></a><strong>Example</strong>:</h5><ul>
<li>The tokens “USA” and “U.S.A.” could be normalized to the same form.</li>
<li><strong>Case folding</strong>: Converting all text to lowercase to unify variations in capitalization.</li>
</ul>
<p>There are other normalization strategies, such as handling accented characters, regional spelling differences, or even creating synonyms lists to account for variations in search queries.</p>
<h4 id="Stemming-and-Lemmatization"><a href="#Stemming-and-Lemmatization" class="headerlink" title="Stemming and Lemmatization"></a>Stemming and Lemmatization</h4><p>The purpose of stemming and lemmatization is to reduce words to their base forms, particularly for languages with rich inflection or derivation.</p>
<ul>
<li><p><strong>Stemming</strong>: Heuristically removes suffixes to produce root forms.</p>
<ul>
<li><strong>Example</strong>: “running” → “run,” “dogs” → “dog”</li>
</ul>
</li>
<li><p><strong>Lemmatization</strong>: Uses linguistic rules to map inflected forms to a canonical dictionary entry, known as a <em>lemma</em>.</p>
<ul>
<li><strong>Example</strong>: “am,” “are,” “is” → “be”</li>
</ul>
</li>
</ul>
<h3 id="0x03-Skip-List-Based-Inverted-Index-Merge-Algorithm"><a href="#0x03-Skip-List-Based-Inverted-Index-Merge-Algorithm" class="headerlink" title="0x03 Skip-List-Based Inverted Index Merge Algorithm"></a>0x03 Skip-List-Based Inverted Index Merge Algorithm</h3><p>A skip list is a data structure used to accelerate the merging of inverted lists by providing pointers that allow the algorithm to skip over irrelevant entries during search operations.</p>
<h5 id="Example-5"><a href="#Example-5" class="headerlink" title="Example:"></a><strong>Example</strong>:</h5><ul>
<li>In a document collection, instead of linearly traversing an entire list, skip pointers are placed every √p positions (where p is the length of the list), speeding up the search.</li>
</ul>
<h3 id="0x04-Inverted-Index-with-Positional-Information-and-Phrase-Queries"><a href="#0x04-Inverted-Index-with-Positional-Information-and-Phrase-Queries" class="headerlink" title="0x04 Inverted Index with Positional Information and Phrase Queries"></a>0x04 Inverted Index with Positional Information and Phrase Queries</h3><h4 id="Biword-Indexing"><a href="#Biword-Indexing" class="headerlink" title="Biword Indexing"></a>Biword Indexing</h4><p>One approach to handling phrase queries is to treat every consecutive pair of words in a document as a phrase, known as a biword.</p>
<h5 id="Example-6"><a href="#Example-6" class="headerlink" title="Example:"></a><strong>Example</strong>:</h5><ul>
<li><strong>Input</strong>: “information retrieval”</li>
<li><strong>Biword index</strong>: “information-retrieval”</li>
</ul>
<h4 id="Positional-Indexing"><a href="#Positional-Indexing" class="headerlink" title="Positional Indexing"></a>Positional Indexing</h4><p>A more common method involves using positional indexes, where each term’s position in a document is stored. This allows for proximity searches, which is not possible with biword indexes alone.</p>
<h4 id="Hybrid-Indexing-Mechanism"><a href="#Hybrid-Indexing-Mechanism" class="headerlink" title="Hybrid Indexing Mechanism"></a>Hybrid Indexing Mechanism</h4><p>A hybrid approach combines biword and positional indexes for efficient phrase querying. For common phrases, biword indexing is used, while for less frequent phrases, positional indexing is preferred.</p>
<h5 id="Example-7"><a href="#Example-7" class="headerlink" title="Example:"></a>Example:</h5><p> High-frequency phrases are added to the biword index, whereas phrases involving very common individual words but rare combinations are handled using positional indexes.</p>
<h3 id="0x05-Summary"><a href="#0x05-Summary" class="headerlink" title="0x05 Summary"></a>0x05 Summary</h3><p>In fact, this chapter is an detailed description of Inverted index introduced in the first chapter. At first, the author listed the specific steps to constract inverted index: First, the document needs to be converted from a byte stream to a character stream, mainly facing the problem of encoding determination and document type conversion. Subsequently, the document is segmented into a token stream, and stop words are removed, and the accuracy of the search is improved through vocabulary normalization. Next, the processing speed of the inverted list is optimized using jump pointers, and the application of bigram indexes and positional indexes in phrase queries is discussed. By combining these two strategies, the system can balance efficiency and accuracy, and improve the search engine’s query capabilities for common phrases and precise phrases.</p>
<h2 id="Chapter-3-Dictionary-and-Fault-Tolerant-Search"><a href="#Chapter-3-Dictionary-and-Fault-Tolerant-Search" class="headerlink" title="Chapter 3: Dictionary and Fault-Tolerant Search"></a><strong>Chapter 3: Dictionary and Fault-Tolerant Search</strong></h2><h3 id="0x00-Data-Structures-for-Dictionary-Search"><a href="#0x00-Data-Structures-for-Dictionary-Search" class="headerlink" title="0x00 Data Structures for Dictionary Search"></a><strong>0x00 Data Structures for Dictionary Search</strong></h3><p><strong>dictionary</strong>:a classical data structure used to look up words , and there are two  ways to implement: <strong>hash tables</strong> and <strong>search trees</strong>.</p>
<p><strong>key</strong>:each entry in the dictionaryis.</p>
<p><strong>Binary Tree</strong>:a tree data structure, where each node has at most two child nodes, the left child node and the right child node. It is often used in fast search and sorting algorithms, but the tree may be unbalanced, resulting in reduced operation efficiency. </p>
<p><img src="C:\Users\zyy23\AppData\Roaming\Typora\typora-user-images\image-20240923112155754.png" alt="image-20240923112155754"></p>
<p><strong>B-tree</strong>：a self-balancing multi-way search tree, where a node can have multiple child nodes. It aims to optimize the insertion, deletion and search operations of large-scale data by maintaining the balance of the tree. It is widely used in databases and file systems to reduce disk access.</p>
<p><img src="C:\Users\zyy23\AppData\Roaming\Typora\typora-user-images\image-20240923111922196.png" alt="image-20240923111922196"></p>
<h3 id="0x01-Wildcard-Queries"><a href="#0x01-Wildcard-Queries" class="headerlink" title="0x01 Wildcard Queries"></a><strong>0x01 Wildcard Queries</strong></h3><p>Wildcard queries are suitable for the following scenarios:</p>
<ol>
<li>The user is unsure about the spelling of the query.</li>
<li>The user knows that the query term might have multiple spelling versions.</li>
<li>The user is looking for all variations of a query term, which may have undergone stemming, but the user is unsure if the search engine has applied stemming.</li>
<li>The user is uncertain about the correct spelling of a foreign word or phrase.</li>
</ol>
<p>If the wildcard <code>*</code> appears only once at the end of a query string, a query like <code>mon*</code> is called a <strong>trailing wildcard query</strong>.</p>
<p>For <strong>leading wildcard queries</strong>, a reverse B-tree structure can be introduced. In this structure, each term in the original B-tree is written backward. After traversing the reverse B-tree, all terms that share the same suffix can be returned.</p>
<p>More general single wildcard queries can be obtained by using both the B-tree and reverse B-tree in combination.</p>
<h4 id="General-Wildcard-Queries"><a href="#General-Wildcard-Queries" class="headerlink" title="General Wildcard Queries"></a><strong>General Wildcard Queries</strong></h4><p>The <strong>permuterm index</strong> is a specialized form of an inverted index for handling general wildcard queries. First, a new symbol <code>$</code> is introduced into the character set to indicate the end of a term.</p>
<p>Next, a permuterm index is constructed, where each rotation of an extended term is associated with a pointer to the original term.</p>
<p>Consider a wildcard query like <code>m*n</code>. The query is rotated to make the <code>*</code> appear at the end of the string, becoming <code>n$m*</code>. The next step is to search for this string in the permuterm index, which is equivalent to searching for rotations of terms like “man” or “moron.”</p>
<p>The biggest drawback of the permuterm index is that the dictionary becomes quite large since it stores all rotations of each term.</p>
<h4 id="k-gram-Index-Supporting-Wildcard-Queries"><a href="#k-gram-Index-Supporting-Wildcard-Queries" class="headerlink" title="k-gram Index Supporting Wildcard Queries"></a><strong>k-gram Index Supporting Wildcard Queries</strong></h4><p>Another technique is the <strong>k-gram index</strong>, which is used for handling wildcard queries. In a k-gram index, the dictionary consists of all k-grams (substrings of length k) from the terms in the vocabulary. Each inverted list contains all terms that include the k-gram.</p>
<p>The k-gram index might return unexpected results, meaning it guarantees recall but not precision. To improve precision, post-filtering is required by performing simple string matching using the original query.</p>
<h3 id="0x02-Spelling-Correction"><a href="#0x02-Spelling-Correction" class="headerlink" title="0x02 Spelling Correction"></a><strong>0x02 Spelling Correction</strong></h3><p>Spelling correction is addressed in two main steps:</p>
<ul>
<li><strong>Edit Distance</strong></li>
<li><strong>k-gram Overlap</strong></li>
</ul>
<h4 id="Implementing-Spelling-Correction"><a href="#Implementing-Spelling-Correction" class="headerlink" title="Implementing Spelling Correction"></a><strong>Implementing Spelling Correction</strong></h4><p>Most spelling correction algorithms follow these two basic principles:</p>
<ol>
<li>For a misspelled query, select the “closest” correct spelling.</li>
<li>If two correct spellings have equal (or nearly equal) proximity, choose the more common one.</li>
</ol>
<p>“More common” can be determined by counting how frequently each term appears in a document set. Many search engines use another definition of “more common”: selecting the most frequent spelling form based on other users’ queries.</p>
<h4 id="Spelling-Correction-Methods"><a href="#Spelling-Correction-Methods" class="headerlink" title="Spelling Correction Methods"></a><strong>Spelling Correction Methods</strong></h4><p>There are two types of spelling correction:</p>
<ul>
<li><p>Isolated-term correction</p>
<p>: Each query term is corrected independently of the others.</p>
<ul>
<li>Edit Distance Method</li>
<li>k-gram Overlap Method</li>
</ul>
</li>
<li><p><strong>Context-sensitive correction</strong></p>
</li>
</ul>
<h4 id="Edit-Distance"><a href="#Edit-Distance" class="headerlink" title="Edit Distance"></a><strong>Edit Distance</strong></h4><p>Given two strings, s1s_1s1 and s2s_2s2, the <strong>edit distance</strong> between them is defined as the minimum number of edit operations needed to convert s1s_1s1 into s2s_2s2.</p>
<p>Edit operations typically include:</p>
<ul>
<li>Inserting a character into a string</li>
<li>Deleting a character from a string</li>
<li>Replacing one character in a string with another</li>
</ul>
<p>This edit distance is also known as the <strong>Levenshtein distance</strong>.</p>
<p>The solution can be approached using dynamic programming, where strings s1s_1s1 and s2s_2s2 are treated as character arrays. The algorithm fills a matrix that stores the edit distances between prefixes of s1s_1s1 and s2s_2s2.</p>
<p>For spelling correction, the task is to find the string from a set VVV (the dictionary) that has the smallest edit distance from the query string qqq.</p>
<h4 id="k-gram-Index-in-Spelling-Correction"><a href="#k-gram-Index-in-Spelling-Correction" class="headerlink" title="k-gram Index in Spelling Correction"></a><strong>k-gram Index in Spelling Correction</strong></h4><p>Using a k-gram index helps find terms that share many common k-grams with the query. The process involves a single scan of the inverted lists of k-grams in the query string qqq.</p>
<p>The k-gram method may return unnecessary correct spellings, so a finer overlap measure, like the <strong>Jaccard coefficient</strong>, can be used to refine the results.</p>
<h4 id="Context-Sensitive-Spelling-Correction"><a href="#Context-Sensitive-Spelling-Correction" class="headerlink" title="Context-Sensitive Spelling Correction"></a><strong>Context-Sensitive Spelling Correction</strong></h4><p>One simple implementation of context-sensitive correction attempts to replace each word in the query with possible correct spellings and then checks the resulting phrase.</p>
<p>To reduce overhead, only high-frequency combinations from document collections or query logs are retained.</p>
<h3 id="0x03-Phonetic-Based-Correction"><a href="#0x03-Phonetic-Based-Correction" class="headerlink" title="0x03 Phonetic-Based Correction"></a><strong>0x03 Phonetic-Based Correction</strong></h3><p>This final fault-tolerant search technique involves <strong>phonetic correction</strong>, where misspelling is due to the user entering a query that sounds similar to the target term. This approach is particularly useful for searching for names.</p>
<p>The core idea is to apply a phonetic hashing operation, where terms that sound similar are mapped to the same value. One such method is the <strong>Soundex algorithm</strong>. The basic steps of the Soundex algorithm are as follows:</p>
<ol>
<li>Convert all terms into a four-character simplified form. An inverted index is built using these forms, called the Soundex index.</li>
<li>Apply the same process to the query term.</li>
<li>When performing a Soundex match, search within the Soundex index.</li>
</ol>
<p>Different variants of this algorithm differ in how terms are converted into the four-character form. One commonly used method results in four-character codes, where the first character is a letter and the remaining three are digits from 0-9. The conversion rules are as follows:</p>
<ol>
<li>Keep the first letter of the term.</li>
<li>Convert all subsequent letters A, E, I, O, U, H, W, and Y to 0.</li>
<li>Apply the following rules for the remaining letters:<ul>
<li>Convert B, F, P, and V to 1.</li>
<li>Convert C, G, J, K, Q, S, X, and Z to 2.</li>
<li>Convert D and T to 3.</li>
<li>Convert L to 4.</li>
<li>Convert M and N to 5.</li>
<li>Convert R to 6.</li>
</ul>
</li>
<li>Replace consecutive occurrences of the same character with a single character until no more repetitions remain.</li>
<li>Remove all 0s from the result string, pad it with 0s at the end if necessary, and return the first four characters, which consist of one letter and three digits.</li>
</ol>
<h3 id="0x04-Summary"><a href="#0x04-Summary" class="headerlink" title="0x04 Summary"></a>0x04 Summary</h3><p>This chapter introduces two primary data structures for dictionary search: hash tables and search trees, particularly focusing on Binary Trees and B-trees. A binary tree allows for fast searches but can become unbalanced, reducing efficiency, while a B-tree maintains balance and is optimized for large-scale data operations, making it ideal for databases.</p>
<p>The chapter also discusses wildcard queries for handling uncertain or variant spellings and introduces permuterm and k-gram indexes to manage these queries. Spelling correction is addressed through two main approaches: edit distance and k-gram overlap, with context-sensitive and phonetic-based methods like the Soundex algorithm used for improving query accuracy. </p>
<h2 id="Chapter-4-Index-Construction"><a href="#Chapter-4-Index-Construction" class="headerlink" title="Chapter 4: Index Construction"></a>Chapter 4: Index Construction</h2><h3 id="0x00-Hardware-Basics"><a href="#0x00-Hardware-Basics" class="headerlink" title="0x00 Hardware Basics"></a>0x00 Hardware Basics</h3><p>When designing an Information Retrieval (IR) system, many decisions are influenced by the computer hardware characteristics. Key concepts include:</p>
<p><strong>Memory vs. Disk Access:</strong> Access to data in memory is much faster than access to data on disk. A byte in memory can be accessed in a few clock cycles (about 5×10⁻⁹ seconds), while transferring it from disk can take significantly longer (about 2×10⁻⁸ seconds). Data that is accessed frequently should therefore be stored in memory to optimize speed.</p>
<p><strong>Seek Time:</strong> During a disk read or write operation, it takes time for the disk head to move to the correct part of the disk (seek time), which averages 5 milliseconds for typical disks. No data is transferred during this time. To optimize transfer rates, data should be stored contiguously on disk to enable efficient sequential reads.</p>
<p><strong>Block Reading:</strong> Operating systems typically read and write entire blocks of data at a time. Block sizes of 8, 16, 32, and 64 kilobytes (KB) are common. Thus, reading a single byte from disk may take as much time as reading an entire block. The part of main memory where a block is read or written is called a <strong>buffer</strong>.</p>
<p><strong>Data Transfers:</strong> Data transfers from disk to memory are managed by the system bus, not the processor. This allows the processor to process other data while disk I&#x2F;O is taking place. We can exploit this by storing compressed data on disk, thereby speeding up overall data transfer.</p>
<h3 id="0x01-Blocked-Sort-Based-Indexing-BSBI"><a href="#0x01-Blocked-Sort-Based-Indexing-BSBI" class="headerlink" title="0x01 Blocked Sort-Based Indexing (BSBI)"></a>0x01 Blocked Sort-Based Indexing (BSBI)</h3><p>When dealing with large collections that require secondary storage, <strong>Blocked Sort-Based Indexing (BSBI)</strong> is an effective external sorting algorithm that minimizes random disk seeks:</p>
<p><strong>Segmenting:</strong> The collection is split into equal-sized parts.</p>
<p><strong>Sorting:</strong> Each part is sorted into termID–docID pairs in memory.</p>
<p><strong>Storing:</strong> Sorted intermediate results are written to disk.</p>
<p><strong>Merging:</strong> Finally, all intermediate results are merged into the final index.</p>
<p>The time complexity of BSBI is <strong>O(TlogT)</strong>, where T is an upper bound on the number of items (termID–docID pairs) to be sorted. However, in practice, the time taken to parse the documents (via <code>ParseNextBlock</code>) and the final merge (<code>MergeBlocks</code>) often dominates the overall indexing time.</p>
<h3 id="0x02-Single-Pass-In-Memory-Indexing-SPIMI"><a href="#0x02-Single-Pass-In-Memory-Indexing-SPIMI" class="headerlink" title="0x02 Single-Pass In-Memory Indexing (SPIMI)"></a>0x02 Single-Pass In-Memory Indexing (SPIMI)</h3><p>While BSBI is efficient, it requires a mapping of terms to termIDs, which might not fit into memory for very large collections. <strong>Single-Pass In-Memory Indexing (SPIMI)</strong> overcomes this issue:</p>
<ul>
<li>SPIMI does not rely on termIDs, allowing it to use terms directly.</li>
<li>Each block’s dictionary is written to disk after processing, and a new dictionary is started for the next block.</li>
<li>It allows the system to index large collections as long as enough disk space is available.</li>
</ul>
<p><strong>Advantages of SPIMI:</strong></p>
<ol>
<li><strong>No Sorting Needed:</strong> SPIMI avoids the need to sort termID–docID pairs, making it faster.</li>
<li><strong>Memory Efficiency:</strong> Instead of keeping track of termIDs, SPIMI associates each postings list with the term itself, reducing memory usage.</li>
</ol>
<p>The time complexity of SPIMI is <strong>O(T)</strong> because it avoids sorting, with all operations linear in the size of the collection.</p>
<h3 id="0x03-Distributed-Indexing-with-MapReduce"><a href="#0x03-Distributed-Indexing-with-MapReduce" class="headerlink" title="0x03 Distributed Indexing with MapReduce"></a>0x03 Distributed Indexing with MapReduce</h3><p>For very large collections, such as the web, a single machine is often insufficient for efficient index construction. Web search engines use <strong>distributed indexing algorithms</strong>, commonly employing <strong>MapReduce</strong>, a framework for distributed computing over large clusters:</p>
<ul>
<li><strong>Map Phase:</strong> The collection is split into parts, and index construction (such as BSBI or SPIMI) is applied to each part.</li>
<li><strong>Reduce Phase:</strong> The segments created during the map phase are then merged into the final index.</li>
</ul>
<p><img src="C:\Users\zyy23\AppData\Roaming\Typora\typora-user-images\image-20240923143142685.png" alt="image-20240923143142685"></p>
<h3 id="0x04-Dynamic-Indexing"><a href="#0x04-Dynamic-Indexing" class="headerlink" title="0x04 Dynamic Indexing"></a>0x04 Dynamic Indexing</h3><p>For collections that change frequently, a dynamic indexing approach is required, ensuring that any additions, deletions, or updates are reflected in the index immediately. A common strategy involves maintaining two indexes:</p>
<ul>
<li><strong>Primary Index:</strong> A larger, static index stored on disk.</li>
<li><strong>Auxiliary Index:</strong> A smaller, in-memory index that captures recent changes.</li>
</ul>
<p>At regular intervals, the auxiliary index is merged with the primary index, maintaining up-to-date search results while efficiently handling frequent updates.</p>
<p><strong>Logarithmic merging:</strong></p>
<p><img src="C:\Users\zyy23\AppData\Roaming\Typora\typora-user-images\image-20240923143424773.png" alt="image-20240923143424773"></p>
<h3 id="0x05-Other-Indexing-Techniques"><a href="#0x05-Other-Indexing-Techniques" class="headerlink" title="0x05 Other Indexing Techniques"></a>0x05 Other Indexing Techniques</h3><p>Different types of indexes serve various needs, from handling large collections to supporting advanced retrieval methods:</p>
<p><strong>Positional Indexing:</strong> In addition to storing termID–docID pairs, positional indexes store the position of each term within the document. This allows for proximity-based searches (e.g., phrase queries).</p>
<p><strong>Ranked Retrieval:</strong> In certain systems, postings lists may store relevance scores or weights for documents. This allows for efficient ranked retrieval, enabling the system to stop once the top results have been identified.</p>
<p><strong>Access Control:</strong> In enterprise search, security measures like <strong>Access Control Lists (ACLs)</strong> ensure that only authorized users can access certain documents. This is often managed by creating separate inverted lists for each user’s permission level.</p>
<h3 id="0x06-Summary"><a href="#0x06-Summary" class="headerlink" title="0x06 Summary"></a>0x06 Summary</h3><p>Indexing algorithms are influenced by hardware constraints, where faster memory access and efficient disk management play critical roles. Blocked sort-based indexing (BSBI) is a scalable single-machine solution that segments and sorts termID-docID pairs in memory before merging them on disk. Single-pass in-memory indexing (SPIMI) improves scalability by eliminating the need to store the entire vocabulary in memory. For large-scale collections, distributed indexing using frameworks like MapReduce is necessary, while dynamic indexing supports real-time updates for constantly changing data. Because memory access is faster than disk access, optimizing memory usage and storing data contiguously on disk are crucial for efficiency. BSBI’s O(TlogT) time complexity highlights the impact of sorting, but most time is spent parsing documents and merging blocks. As data scales, the integration of distributed, dynamic, and hybrid indexing methods will be vital for sustaining real-time search performance while mitigating hardware limitations.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://example.com">yuyz</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://example.com/2024/09/09/Information-Retrieval-note/">http://example.com/2024/09/09/Information-Retrieval-note/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/09/10/%E8%93%9D%E9%98%9F/" title="蓝队"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">蓝队</div></div></a></div><div class="next-post pull-right"><a href="/2024/08/23/Linux-%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/" title="Linux 学习入门指南"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next</div><div class="next_info">Linux 学习入门指南</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">yuyz</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Information-Retrieval"><span class="toc-number">1.</span> <span class="toc-text">Information Retrieval</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-1"><span class="toc-number">1.1.</span> <span class="toc-text">Chapter 1</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#0x00-Information-Retrieval-and-Some-Concept"><span class="toc-number">1.1.1.</span> <span class="toc-text">0x00 Information Retrieval and Some Concept</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#The-Goal-of-Information-Retrieval"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">The Goal of Information Retrieval</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Definition-of-Information-Retrieval"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">Definition of Information Retrieval</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Use-cases-of-Information-Retrieval"><span class="toc-number">1.1.1.3.</span> <span class="toc-text">Use cases of Information Retrieval</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Ad-hoc-retrieval-task"><span class="toc-number">1.1.1.3.1.</span> <span class="toc-text">Ad hoc retrieval task:</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#How-to-Evaluating-the-effectiveness-of-a-retrieval-system-the-quality-of-search-results-%EF%BC%9A"><span class="toc-number">1.1.1.4.</span> <span class="toc-text">How to Evaluating the effectiveness of a retrieval system (the quality of search results)：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#some-nouns"><span class="toc-number">1.1.2.</span> <span class="toc-text">some nouns</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#corpus"><span class="toc-number">1.1.2.0.1.</span> <span class="toc-text">corpus</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Term-document-incidence-matrix"><span class="toc-number">1.1.2.0.2.</span> <span class="toc-text">Term-document incidence matrix</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x01-inverted-index"><span class="toc-number">1.1.3.</span> <span class="toc-text">0x01 inverted index</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x02-Boolean-retrieval-model"><span class="toc-number">1.1.4.</span> <span class="toc-text">0x02 Boolean retrieval model</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Boolean-retrieval-model"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">Boolean retrieval model</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Query-optimization"><span class="toc-number">1.1.4.2.</span> <span class="toc-text">Query optimization</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x03-The-extended-Boolean-model-versus-ranked-retrieval"><span class="toc-number">1.1.5.</span> <span class="toc-text">0x03 The extended Boolean model versus ranked retrieval</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ranked-retrieval-model"><span class="toc-number">1.1.5.1.</span> <span class="toc-text">ranked retrieval model</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#proximity-operator"><span class="toc-number">1.1.5.2.</span> <span class="toc-text">proximity operator</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#A-common-issue-with-Boolean-search"><span class="toc-number">1.1.5.3.</span> <span class="toc-text">A common issue with Boolean search</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x04-Summarize"><span class="toc-number">1.1.6.</span> <span class="toc-text">0x04 Summarize</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-2-Lexicon-and-Inverted-Index"><span class="toc-number">1.2.</span> <span class="toc-text">Chapter 2: Lexicon and Inverted Index</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#0x00-Introduction"><span class="toc-number">1.2.1.</span> <span class="toc-text">0x00 Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#content"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">content</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Key-words"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">Key words</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x01-Document-Analysis-and-Encoding-Conversion"><span class="toc-number">1.2.2.</span> <span class="toc-text">0x01 Document Analysis and Encoding Conversion</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Character-Sequence-Generation"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">Character Sequence Generation</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Example"><span class="toc-number">1.2.2.1.1.</span> <span class="toc-text">Example:</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Selection-of-Document-Units"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">Selection of Document Units</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Example-1"><span class="toc-number">1.2.2.2.1.</span> <span class="toc-text">Example:</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x02-Defining-the-Term-Set"><span class="toc-number">1.2.3.</span> <span class="toc-text">0x02 Defining the Term Set</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Tokenization"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">Tokenization</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Example-2"><span class="toc-number">1.2.3.1.1.</span> <span class="toc-text">Example:</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Removing-Stop-Words"><span class="toc-number">1.2.3.2.</span> <span class="toc-text">Removing Stop Words</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Example-3"><span class="toc-number">1.2.3.2.1.</span> <span class="toc-text">Example:</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Token-Normalization"><span class="toc-number">1.2.3.3.</span> <span class="toc-text">Token Normalization</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Example-4"><span class="toc-number">1.2.3.3.1.</span> <span class="toc-text">Example:</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Stemming-and-Lemmatization"><span class="toc-number">1.2.3.4.</span> <span class="toc-text">Stemming and Lemmatization</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x03-Skip-List-Based-Inverted-Index-Merge-Algorithm"><span class="toc-number">1.2.4.</span> <span class="toc-text">0x03 Skip-List-Based Inverted Index Merge Algorithm</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Example-5"><span class="toc-number">1.2.4.0.1.</span> <span class="toc-text">Example:</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x04-Inverted-Index-with-Positional-Information-and-Phrase-Queries"><span class="toc-number">1.2.5.</span> <span class="toc-text">0x04 Inverted Index with Positional Information and Phrase Queries</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Biword-Indexing"><span class="toc-number">1.2.5.1.</span> <span class="toc-text">Biword Indexing</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Example-6"><span class="toc-number">1.2.5.1.1.</span> <span class="toc-text">Example:</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Positional-Indexing"><span class="toc-number">1.2.5.2.</span> <span class="toc-text">Positional Indexing</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Hybrid-Indexing-Mechanism"><span class="toc-number">1.2.5.3.</span> <span class="toc-text">Hybrid Indexing Mechanism</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Example-7"><span class="toc-number">1.2.5.3.1.</span> <span class="toc-text">Example:</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x05-Summary"><span class="toc-number">1.2.6.</span> <span class="toc-text">0x05 Summary</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-3-Dictionary-and-Fault-Tolerant-Search"><span class="toc-number">1.3.</span> <span class="toc-text">Chapter 3: Dictionary and Fault-Tolerant Search</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#0x00-Data-Structures-for-Dictionary-Search"><span class="toc-number">1.3.1.</span> <span class="toc-text">0x00 Data Structures for Dictionary Search</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x01-Wildcard-Queries"><span class="toc-number">1.3.2.</span> <span class="toc-text">0x01 Wildcard Queries</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#General-Wildcard-Queries"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">General Wildcard Queries</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#k-gram-Index-Supporting-Wildcard-Queries"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">k-gram Index Supporting Wildcard Queries</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x02-Spelling-Correction"><span class="toc-number">1.3.3.</span> <span class="toc-text">0x02 Spelling Correction</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Implementing-Spelling-Correction"><span class="toc-number">1.3.3.1.</span> <span class="toc-text">Implementing Spelling Correction</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Spelling-Correction-Methods"><span class="toc-number">1.3.3.2.</span> <span class="toc-text">Spelling Correction Methods</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Edit-Distance"><span class="toc-number">1.3.3.3.</span> <span class="toc-text">Edit Distance</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#k-gram-Index-in-Spelling-Correction"><span class="toc-number">1.3.3.4.</span> <span class="toc-text">k-gram Index in Spelling Correction</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Context-Sensitive-Spelling-Correction"><span class="toc-number">1.3.3.5.</span> <span class="toc-text">Context-Sensitive Spelling Correction</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x03-Phonetic-Based-Correction"><span class="toc-number">1.3.4.</span> <span class="toc-text">0x03 Phonetic-Based Correction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x04-Summary"><span class="toc-number">1.3.5.</span> <span class="toc-text">0x04 Summary</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-4-Index-Construction"><span class="toc-number">1.4.</span> <span class="toc-text">Chapter 4: Index Construction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#0x00-Hardware-Basics"><span class="toc-number">1.4.1.</span> <span class="toc-text">0x00 Hardware Basics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x01-Blocked-Sort-Based-Indexing-BSBI"><span class="toc-number">1.4.2.</span> <span class="toc-text">0x01 Blocked Sort-Based Indexing (BSBI)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x02-Single-Pass-In-Memory-Indexing-SPIMI"><span class="toc-number">1.4.3.</span> <span class="toc-text">0x02 Single-Pass In-Memory Indexing (SPIMI)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x03-Distributed-Indexing-with-MapReduce"><span class="toc-number">1.4.4.</span> <span class="toc-text">0x03 Distributed Indexing with MapReduce</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x04-Dynamic-Indexing"><span class="toc-number">1.4.5.</span> <span class="toc-text">0x04 Dynamic Indexing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x05-Other-Indexing-Techniques"><span class="toc-number">1.4.6.</span> <span class="toc-text">0x05 Other Indexing Techniques</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0x06-Summary"><span class="toc-number">1.4.7.</span> <span class="toc-text">0x06 Summary</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/10/%E8%93%9D%E9%98%9F/" title="蓝队">蓝队</a><time datetime="2024-09-10T06:06:01.000Z" title="Created 2024-09-10 14:06:01">2024-09-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/09/Information-Retrieval-note/" title="Information Retrieval note">Information Retrieval note</a><time datetime="2024-09-09T14:02:06.000Z" title="Created 2024-09-09 22:02:06">2024-09-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/08/23/Linux-%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/" title="Linux 学习入门指南">Linux 学习入门指南</a><time datetime="2024-08-23T04:46:21.000Z" title="Created 2024-08-23 12:46:21">2024-08-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/08/23/Conda-%E5%85%B3%E9%94%AE%E5%91%BD%E4%BB%A4/" title="Conda 关键命令">Conda 关键命令</a><time datetime="2024-08-23T04:45:01.000Z" title="Created 2024-08-23 12:45:01">2024-08-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/08/12/Bash-%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4/" title="Bash 常见命令">Bash 常见命令</a><time datetime="2024-08-12T13:04:38.000Z" title="Created 2024-08-12 21:04:38">2024-08-12</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By yuyz</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>